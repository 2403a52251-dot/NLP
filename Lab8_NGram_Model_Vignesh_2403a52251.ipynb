{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfsKQ5HO9+dawNawYrCeb3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2403a52251-dot/NLP/blob/main/Lab8_NGram_Model_Vignesh_2403a52251.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CORPUS**"
      ],
      "metadata": {
        "id": "vIOAcI-nQe1N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tzVQSB9RIVal"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"Lab8_NGram_Corpus.csv\")\n",
        "display(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "olO5hqyGPk-o",
        "outputId": "8b0117bf-1861-4dca-ba50-fbe9a7f756fe"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                text\n",
              "0  Artificial intelligence is transforming the mo...\n",
              "1  Machine learning algorithms are widely used in...\n",
              "2  Deep learning models such as convolutional neu...\n",
              "3  Quantum computing introduces qubits, superposi...\n",
              "4  Cybersecurity protects organizations from rans...\n",
              "5  Blockchain technology ensures decentralized le...\n",
              "6  Renewable energy sources include solar photovo...\n",
              "7  Bioinformatics integrates genomics, proteomics...\n",
              "8  Astrophysics studies dark matter, black holes,...\n",
              "9  Nanotechnology enhances material engineering a..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ca645ee9-749e-4903-85c8-8ea393f8d998\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Artificial intelligence is transforming the mo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Machine learning algorithms are widely used in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Deep learning models such as convolutional neu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Quantum computing introduces qubits, superposi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Cybersecurity protects organizations from rans...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Blockchain technology ensures decentralized le...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Renewable energy sources include solar photovo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Bioinformatics integrates genomics, proteomics...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Astrophysics studies dark matter, black holes,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Nanotechnology enhances material engineering a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ca645ee9-749e-4903-85c8-8ea393f8d998')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ca645ee9-749e-4903-85c8-8ea393f8d998 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ca645ee9-749e-4903-85c8-8ea393f8d998');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_6794a437-3367-40a6-8e64-4ac528a3860a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6794a437-3367-40a6-8e64-4ac528a3860a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Astrophysics studies dark matter, black holes, neutron stars, and distant exoplanets.\",\n          \"Machine learning algorithms are widely used in predictive analytics and automation systems.\",\n          \"Blockchain technology ensures decentralized ledger integrity and transparency in cryptocurrency markets.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Uni Gram Counts**"
      ],
      "metadata": {
        "id": "IowVK2BLQmrO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import re\n",
        "\n",
        "# Assuming df is already loaded and contains a 'text' column\n",
        "corpus_text = ' '.join(df['text'].dropna().astype(str))\n",
        "\n",
        "# Tokenize the corpus: convert to lowercase and split by non-alphanumeric characters\n",
        "tokens = re.findall(r'\\b\\w+\\b', corpus_text.lower())\n",
        "\n",
        "words = tokens\n",
        "\n",
        "unigram_counts = collections.Counter(words)\n",
        "\n",
        "print(\"Unigram Counts:\")\n",
        "for word, count in unigram_counts.most_common():\n",
        "    print(f\"{word}: {count}\")\n",
        "V=len(unigram_counts)\n",
        "print(\"Vocabulary Size=\",V)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEGT6LPJIiZa",
        "outputId": "1ba54c36-41ab-4276-dd3b-21913c88d46b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigram Counts:\n",
            "and: 10\n",
            "the: 2\n",
            "technology: 2\n",
            "learning: 2\n",
            "in: 2\n",
            "systems: 2\n",
            "for: 2\n",
            "artificial: 1\n",
            "intelligence: 1\n",
            "is: 1\n",
            "transforming: 1\n",
            "modern: 1\n",
            "world: 1\n",
            "of: 1\n",
            "research: 1\n",
            "machine: 1\n",
            "algorithms: 1\n",
            "are: 1\n",
            "widely: 1\n",
            "used: 1\n",
            "predictive: 1\n",
            "analytics: 1\n",
            "automation: 1\n",
            "deep: 1\n",
            "models: 1\n",
            "such: 1\n",
            "as: 1\n",
            "convolutional: 1\n",
            "neural: 1\n",
            "networks: 1\n",
            "transformers: 1\n",
            "power: 1\n",
            "computer: 1\n",
            "vision: 1\n",
            "applications: 1\n",
            "quantum: 1\n",
            "computing: 1\n",
            "introduces: 1\n",
            "qubits: 1\n",
            "superposition: 1\n",
            "entanglement: 1\n",
            "principles: 1\n",
            "advanced: 1\n",
            "computation: 1\n",
            "cybersecurity: 1\n",
            "protects: 1\n",
            "organizations: 1\n",
            "from: 1\n",
            "ransomware: 1\n",
            "phishing: 1\n",
            "malware: 1\n",
            "zero: 1\n",
            "day: 1\n",
            "exploits: 1\n",
            "blockchain: 1\n",
            "ensures: 1\n",
            "decentralized: 1\n",
            "ledger: 1\n",
            "integrity: 1\n",
            "transparency: 1\n",
            "cryptocurrency: 1\n",
            "markets: 1\n",
            "renewable: 1\n",
            "energy: 1\n",
            "sources: 1\n",
            "include: 1\n",
            "solar: 1\n",
            "photovoltaics: 1\n",
            "wind: 1\n",
            "turbines: 1\n",
            "geothermal: 1\n",
            "tidal: 1\n",
            "generators: 1\n",
            "bioinformatics: 1\n",
            "integrates: 1\n",
            "genomics: 1\n",
            "proteomics: 1\n",
            "computational: 1\n",
            "biology: 1\n",
            "medical: 1\n",
            "discoveries: 1\n",
            "astrophysics: 1\n",
            "studies: 1\n",
            "dark: 1\n",
            "matter: 1\n",
            "black: 1\n",
            "holes: 1\n",
            "neutron: 1\n",
            "stars: 1\n",
            "distant: 1\n",
            "exoplanets: 1\n",
            "nanotechnology: 1\n",
            "enhances: 1\n",
            "material: 1\n",
            "engineering: 1\n",
            "at: 1\n",
            "molecular: 1\n",
            "atomic: 1\n",
            "scale: 1\n",
            "Vocabulary Size= 99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bi-Gram counts**"
      ],
      "metadata": {
        "id": "e0PGp-K5RwF4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "words = tokens # Using the already defined 'tokens' list\n",
        "\n",
        "bigrams = []\n",
        "for i in range(len(words) - 1):\n",
        "    bigrams.append((words[i], words[i+1]))\n",
        "\n",
        "bigram_counts = collections.Counter(bigrams)\n",
        "\n",
        "print(\"\\nBigram Counts:\")\n",
        "for bigram, count in bigram_counts.most_common():\n",
        "    print(f\"{bigram[0]} {bigram[1]}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yL2d7a3Otxz0",
        "outputId": "b3c112a4-6853-4df8-e5cd-ed3317b73b17"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Bigram Counts:\n",
            "artificial intelligence: 1\n",
            "intelligence is: 1\n",
            "is transforming: 1\n",
            "transforming the: 1\n",
            "the modern: 1\n",
            "modern world: 1\n",
            "world of: 1\n",
            "of technology: 1\n",
            "technology and: 1\n",
            "and research: 1\n",
            "research machine: 1\n",
            "machine learning: 1\n",
            "learning algorithms: 1\n",
            "algorithms are: 1\n",
            "are widely: 1\n",
            "widely used: 1\n",
            "used in: 1\n",
            "in predictive: 1\n",
            "predictive analytics: 1\n",
            "analytics and: 1\n",
            "and automation: 1\n",
            "automation systems: 1\n",
            "systems deep: 1\n",
            "deep learning: 1\n",
            "learning models: 1\n",
            "models such: 1\n",
            "such as: 1\n",
            "as convolutional: 1\n",
            "convolutional neural: 1\n",
            "neural networks: 1\n",
            "networks and: 1\n",
            "and transformers: 1\n",
            "transformers power: 1\n",
            "power computer: 1\n",
            "computer vision: 1\n",
            "vision applications: 1\n",
            "applications quantum: 1\n",
            "quantum computing: 1\n",
            "computing introduces: 1\n",
            "introduces qubits: 1\n",
            "qubits superposition: 1\n",
            "superposition and: 1\n",
            "and entanglement: 1\n",
            "entanglement principles: 1\n",
            "principles for: 1\n",
            "for advanced: 1\n",
            "advanced computation: 1\n",
            "computation cybersecurity: 1\n",
            "cybersecurity protects: 1\n",
            "protects organizations: 1\n",
            "organizations from: 1\n",
            "from ransomware: 1\n",
            "ransomware phishing: 1\n",
            "phishing malware: 1\n",
            "malware and: 1\n",
            "and zero: 1\n",
            "zero day: 1\n",
            "day exploits: 1\n",
            "exploits blockchain: 1\n",
            "blockchain technology: 1\n",
            "technology ensures: 1\n",
            "ensures decentralized: 1\n",
            "decentralized ledger: 1\n",
            "ledger integrity: 1\n",
            "integrity and: 1\n",
            "and transparency: 1\n",
            "transparency in: 1\n",
            "in cryptocurrency: 1\n",
            "cryptocurrency markets: 1\n",
            "markets renewable: 1\n",
            "renewable energy: 1\n",
            "energy sources: 1\n",
            "sources include: 1\n",
            "include solar: 1\n",
            "solar photovoltaics: 1\n",
            "photovoltaics wind: 1\n",
            "wind turbines: 1\n",
            "turbines geothermal: 1\n",
            "geothermal systems: 1\n",
            "systems and: 1\n",
            "and tidal: 1\n",
            "tidal generators: 1\n",
            "generators bioinformatics: 1\n",
            "bioinformatics integrates: 1\n",
            "integrates genomics: 1\n",
            "genomics proteomics: 1\n",
            "proteomics and: 1\n",
            "and computational: 1\n",
            "computational biology: 1\n",
            "biology for: 1\n",
            "for medical: 1\n",
            "medical discoveries: 1\n",
            "discoveries astrophysics: 1\n",
            "astrophysics studies: 1\n",
            "studies dark: 1\n",
            "dark matter: 1\n",
            "matter black: 1\n",
            "black holes: 1\n",
            "holes neutron: 1\n",
            "neutron stars: 1\n",
            "stars and: 1\n",
            "and distant: 1\n",
            "distant exoplanets: 1\n",
            "exoplanets nanotechnology: 1\n",
            "nanotechnology enhances: 1\n",
            "enhances material: 1\n",
            "material engineering: 1\n",
            "engineering at: 1\n",
            "at the: 1\n",
            "the molecular: 1\n",
            "molecular and: 1\n",
            "and atomic: 1\n",
            "atomic scale: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Tri-Gram Counts**"
      ],
      "metadata": {
        "id": "mLa3KWPBTT9P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "words = tokens # Using the already defined 'tokens' list\n",
        "\n",
        "Trigrams = []\n",
        "for i in range(len(words) - 2):\n",
        "    Trigrams.append((words[i], words[i+1], words[i+2]))\n",
        "\n",
        "Trigrams_counts = collections.Counter(Trigrams)\n",
        "\n",
        "print(\"\\nTrigrams Counts:\")\n",
        "for Trigrams, count in Trigrams_counts.most_common():\n",
        "    print(f\"{Trigrams[0]} {Trigrams[1]} {Trigrams[2]}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8N_WYJKpIsra",
        "outputId": "953716f9-265c-45e7-8884-ec4b910e53a2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trigrams Counts:\n",
            "artificial intelligence is: 1\n",
            "intelligence is transforming: 1\n",
            "is transforming the: 1\n",
            "transforming the modern: 1\n",
            "the modern world: 1\n",
            "modern world of: 1\n",
            "world of technology: 1\n",
            "of technology and: 1\n",
            "technology and research: 1\n",
            "and research machine: 1\n",
            "research machine learning: 1\n",
            "machine learning algorithms: 1\n",
            "learning algorithms are: 1\n",
            "algorithms are widely: 1\n",
            "are widely used: 1\n",
            "widely used in: 1\n",
            "used in predictive: 1\n",
            "in predictive analytics: 1\n",
            "predictive analytics and: 1\n",
            "analytics and automation: 1\n",
            "and automation systems: 1\n",
            "automation systems deep: 1\n",
            "systems deep learning: 1\n",
            "deep learning models: 1\n",
            "learning models such: 1\n",
            "models such as: 1\n",
            "such as convolutional: 1\n",
            "as convolutional neural: 1\n",
            "convolutional neural networks: 1\n",
            "neural networks and: 1\n",
            "networks and transformers: 1\n",
            "and transformers power: 1\n",
            "transformers power computer: 1\n",
            "power computer vision: 1\n",
            "computer vision applications: 1\n",
            "vision applications quantum: 1\n",
            "applications quantum computing: 1\n",
            "quantum computing introduces: 1\n",
            "computing introduces qubits: 1\n",
            "introduces qubits superposition: 1\n",
            "qubits superposition and: 1\n",
            "superposition and entanglement: 1\n",
            "and entanglement principles: 1\n",
            "entanglement principles for: 1\n",
            "principles for advanced: 1\n",
            "for advanced computation: 1\n",
            "advanced computation cybersecurity: 1\n",
            "computation cybersecurity protects: 1\n",
            "cybersecurity protects organizations: 1\n",
            "protects organizations from: 1\n",
            "organizations from ransomware: 1\n",
            "from ransomware phishing: 1\n",
            "ransomware phishing malware: 1\n",
            "phishing malware and: 1\n",
            "malware and zero: 1\n",
            "and zero day: 1\n",
            "zero day exploits: 1\n",
            "day exploits blockchain: 1\n",
            "exploits blockchain technology: 1\n",
            "blockchain technology ensures: 1\n",
            "technology ensures decentralized: 1\n",
            "ensures decentralized ledger: 1\n",
            "decentralized ledger integrity: 1\n",
            "ledger integrity and: 1\n",
            "integrity and transparency: 1\n",
            "and transparency in: 1\n",
            "transparency in cryptocurrency: 1\n",
            "in cryptocurrency markets: 1\n",
            "cryptocurrency markets renewable: 1\n",
            "markets renewable energy: 1\n",
            "renewable energy sources: 1\n",
            "energy sources include: 1\n",
            "sources include solar: 1\n",
            "include solar photovoltaics: 1\n",
            "solar photovoltaics wind: 1\n",
            "photovoltaics wind turbines: 1\n",
            "wind turbines geothermal: 1\n",
            "turbines geothermal systems: 1\n",
            "geothermal systems and: 1\n",
            "systems and tidal: 1\n",
            "and tidal generators: 1\n",
            "tidal generators bioinformatics: 1\n",
            "generators bioinformatics integrates: 1\n",
            "bioinformatics integrates genomics: 1\n",
            "integrates genomics proteomics: 1\n",
            "genomics proteomics and: 1\n",
            "proteomics and computational: 1\n",
            "and computational biology: 1\n",
            "computational biology for: 1\n",
            "biology for medical: 1\n",
            "for medical discoveries: 1\n",
            "medical discoveries astrophysics: 1\n",
            "discoveries astrophysics studies: 1\n",
            "astrophysics studies dark: 1\n",
            "studies dark matter: 1\n",
            "dark matter black: 1\n",
            "matter black holes: 1\n",
            "black holes neutron: 1\n",
            "holes neutron stars: 1\n",
            "neutron stars and: 1\n",
            "stars and distant: 1\n",
            "and distant exoplanets: 1\n",
            "distant exoplanets nanotechnology: 1\n",
            "exoplanets nanotechnology enhances: 1\n",
            "nanotechnology enhances material: 1\n",
            "enhances material engineering: 1\n",
            "material engineering at: 1\n",
            "engineering at the: 1\n",
            "at the molecular: 1\n",
            "the molecular and: 1\n",
            "molecular and atomic: 1\n",
            "and atomic scale: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next Word Prediction Using Bi-Gram Counts"
      ],
      "metadata": {
        "id": "b85lPYDtiVWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_bigram(word_sequence, bigram_counts, unigram_counts):\n",
        "    # Tokenize the input sequence and get the last word\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "    last_word = words_in_sequence[-1]\n",
        "\n",
        "    # Find potential next words based on bigrams starting with last_word\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2), count in bigram_counts.items():\n",
        "        if w1 == last_word:\n",
        "            potential_next_words[w2] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No bigram found starting with '{last_word}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w2 | w1) = Count(w1, w2) / Count(w1)\n",
        "    last_word_unigram_count = unigram_counts.get(last_word, 0)\n",
        "    if last_word_unigram_count == 0:\n",
        "        return f\"'{last_word}' not found in unigram counts. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, bigram_count in potential_next_words.items():\n",
        "        probability = bigram_count / last_word_unigram_count\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts and unigram_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"biology for\"\n",
        "next_word1 = predict_next_word_bigram(sequence1, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"zero day\"\n",
        "next_word2 = predict_next_word_bigram(sequence2, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n",
        "\n",
        "sequence3 = \"artificial intelligence\"\n",
        "next_word3 = predict_next_word_bigram(sequence3, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence3}', predicted next word: '{next_word3}'\")\n",
        "\n",
        "sequence4 = \"transparency in\"\n",
        "next_word4 = predict_next_word_bigram(sequence4, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence4}', predicted next word: '{next_word4}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hsw2ercai9M",
        "outputId": "771251df-a7b5-4e80-f806-3bbb8fe7fb15"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of  advanced is  0.5\n",
            "probability of  medical is  0.5\n",
            "Given sequence: 'biology for', predicted next word: 'advanced'\n",
            "probability of  exploits is  1.0\n",
            "Given sequence: 'zero day', predicted next word: 'exploits'\n",
            "probability of  is is  1.0\n",
            "Given sequence: 'artificial intelligence', predicted next word: 'is'\n",
            "probability of  predictive is  0.5\n",
            "probability of  cryptocurrency is  0.5\n",
            "Given sequence: 'transparency in', predicted next word: 'predictive'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deployment of Bi-Gram Model**"
      ],
      "metadata": {
        "id": "vh9Afg2ej4j9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_bigram(ip_text, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUFNaxfNcsFC",
        "outputId": "f56cda4d-a313-4eef-f4a2-ebffab619c70"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textstars and\n",
            "probability of  research is  0.1\n",
            "probability of  automation is  0.1\n",
            "probability of  transformers is  0.1\n",
            "probability of  entanglement is  0.1\n",
            "probability of  zero is  0.1\n",
            "probability of  transparency is  0.1\n",
            "probability of  tidal is  0.1\n",
            "probability of  computational is  0.1\n",
            "probability of  distant is  0.1\n",
            "probability of  atomic is  0.1\n",
            "Given sequence: 'stars and', predicted next word: 'research'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Next Word Prediction Using Tri-Gram Counts**"
      ],
      "metadata": {
        "id": "dld1a3-Bj8MU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_trigram(word_sequence, Trigrams_counts, bigram_counts):\n",
        "    # Tokenize the input sequence\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "\n",
        "    # Ensure at least two words for trigram prediction\n",
        "    if len(words_in_sequence) < 2:\n",
        "        return \"Sequence must contain at least two words for trigram prediction.\"\n",
        "\n",
        "    # Get the last two words as a tuple\n",
        "    last_two_words_tuple = tuple(words_in_sequence[-2:])\n",
        "\n",
        "    # Find potential next words based on trigrams starting with the last two words\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2, w3), count in Trigrams_counts.items():\n",
        "        if (w1, w2) == last_two_words_tuple:\n",
        "            potential_next_words[w3] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No trigram found starting with '{' '.join(last_two_words_tuple)}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w3 | w1,w2) = Count(w1, w2, w3) / Count(w1, w2)\n",
        "    # The denominator should be the count of the bigram (w1, w2)\n",
        "    last_two_words_bigram_count = bigram_counts.get(last_two_words_tuple, 0)\n",
        "    if last_two_words_bigram_count == 0:\n",
        "        return f\"'{' '.join(last_two_words_tuple)}' not found as a bigram. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, trigram_count in potential_next_words.items():\n",
        "        probability = trigram_count / last_two_words_bigram_count\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts, unigram_counts, and Trigrams_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"Machine learning algorithms\"\n",
        "next_word1 = predict_next_word_trigram(sequence1, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"and tidal generators\"\n",
        "next_word2 = predict_next_word_trigram(sequence2, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tun202a5c-nx",
        "outputId": "8f11068e-dc4c-43df-e5c1-efe1ee826988"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of  are is  1.0\n",
            "Given sequence: 'Machine learning algorithms', predicted next word: 'are'\n",
            "probability of  bioinformatics is  1.0\n",
            "Given sequence: 'and tidal generators', predicted next word: 'bioinformatics'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deployment of Tri-Gram Model**"
      ],
      "metadata": {
        "id": "zDPypo4gkEyM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_trigram(ip_text, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihahuzcyhe7P",
        "outputId": "c6d765fd-d13a-4bab-9657-dcfd3acf93e2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textsystems and tidal\n",
            "probability of  generators is  1.0\n",
            "Given sequence: 'systems and tidal', predicted next word: 'generators'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Next Word Prediction Using Bi-Gram Counts with Laplace Smoothening**"
      ],
      "metadata": {
        "id": "3E1y8oQVkUeU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_bigram_Laplace(word_sequence, bigram_counts, unigram_counts):\n",
        "    # Tokenize the input sequence and get the last word\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "    last_word = words_in_sequence[-1]\n",
        "\n",
        "    # Find potential next words based on bigrams starting with last_word\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2), count in bigram_counts.items():\n",
        "        if w1 == last_word:\n",
        "            potential_next_words[w2] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No bigram found starting with '{last_word}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w2 | w1) = Count(w1, w2) / Count(w1)\n",
        "    last_word_unigram_count = unigram_counts.get(last_word, 0)\n",
        "    if last_word_unigram_count == 0:\n",
        "        return f\"'{last_word}' not found in unigram counts. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, bigram_count in potential_next_words.items():\n",
        "        probability = (bigram_count+1) / (last_word_unigram_count+V)\n",
        "        print(\"probability of \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts and unigram_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"biology for\"\n",
        "next_word1 = predict_next_word_bigram_Laplace(sequence1, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"zero day\"\n",
        "next_word2 = predict_next_word_bigram_Laplace(sequence2, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n",
        "\n",
        "sequence3 = \"artificial intelligence\"\n",
        "next_word3 = predict_next_word_bigram_Laplace(sequence3, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence3}', predicted next word: '{next_word3}'\")\n",
        "\n",
        "sequence4 = \"transparency in\"\n",
        "next_word4 = predict_next_word_bigram_Laplace(sequence4, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence4}', predicted next word: '{next_word4}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UEQ-55Hfkho",
        "outputId": "ddf4459b-13d3-4106-8318-385943459325"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of advanced is  0.019801980198019802\n",
            "probability of medical is  0.019801980198019802\n",
            "Given sequence: 'biology for', predicted next word: 'advanced'\n",
            "probability of exploits is  0.02\n",
            "Given sequence: 'zero day', predicted next word: 'exploits'\n",
            "probability of is is  0.02\n",
            "Given sequence: 'artificial intelligence', predicted next word: 'is'\n",
            "probability of predictive is  0.019801980198019802\n",
            "probability of cryptocurrency is  0.019801980198019802\n",
            "Given sequence: 'transparency in', predicted next word: 'predictive'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deployment of Laplace Smoothening based Bi-Gram Model**"
      ],
      "metadata": {
        "id": "5yS8cjw9lLlb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_bigram_Laplace(ip_text, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4BQbeCzhHm3",
        "outputId": "99aac85b-3c21-45eb-f02f-882bc7759562"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textstars and\n",
            "probability of research is  0.01834862385321101\n",
            "probability of automation is  0.01834862385321101\n",
            "probability of transformers is  0.01834862385321101\n",
            "probability of entanglement is  0.01834862385321101\n",
            "probability of zero is  0.01834862385321101\n",
            "probability of transparency is  0.01834862385321101\n",
            "probability of tidal is  0.01834862385321101\n",
            "probability of computational is  0.01834862385321101\n",
            "probability of distant is  0.01834862385321101\n",
            "probability of atomic is  0.01834862385321101\n",
            "Given sequence: 'stars and', predicted next word: 'research'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Next Word Prediction Using Tri-Gram Counts based on laplace smoothening**"
      ],
      "metadata": {
        "id": "pq-buR7Il-XL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_trigram_Laplace(word_sequence, Trigrams_counts, bigram_counts):\n",
        "    # Tokenize the input sequence\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "\n",
        "    # Ensure at least two words for trigram prediction\n",
        "    if len(words_in_sequence) < 2:\n",
        "        return \"Sequence must contain at least two words for trigram prediction.\"\n",
        "\n",
        "    # Get the last two words as a tuple\n",
        "    last_two_words_tuple = tuple(words_in_sequence[-2:])\n",
        "\n",
        "    # Find potential next words based on trigrams starting with the last two words\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2, w3), count in Trigrams_counts.items():\n",
        "        if (w1, w2) == last_two_words_tuple:\n",
        "            potential_next_words[w3] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No trigram found starting with '{' '.join(last_two_words_tuple)}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w3 | w1,w2) = Count(w1, w2, w3) / Count(w1, w2)\n",
        "    # The denominator should be the count of the bigram (w1, w2)\n",
        "    last_two_words_bigram_count = bigram_counts.get(last_two_words_tuple, 0)\n",
        "    if last_two_words_bigram_count == 0:\n",
        "        return f\"'{' '.join(last_two_words_tuple)}' not found as a bigram. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, trigram_count in potential_next_words.items():\n",
        "        probability = (trigram_count+1) / (last_two_words_bigram_count+V)\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts, unigram_counts, and Trigrams_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 =\"Machine learning algorithms\"\n",
        "next_word1 = predict_next_word_trigram_Laplace(sequence1, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"and tidal generators\"\n",
        "next_word2 = predict_next_word_trigram_Laplace(sequence2, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nz-Fzd02lYAz",
        "outputId": "f00a621d-aceb-43f0-c7a1-194511a4420e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of  are is  0.02\n",
            "Given sequence: 'Machine learning algorithms', predicted next word: 'are'\n",
            "probability of  bioinformatics is  0.02\n",
            "Given sequence: 'and tidal generators', predicted next word: 'bioinformatics'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deployment of Laplace Smoothening based Tri-Gram Model**"
      ],
      "metadata": {
        "id": "H1yta3XVmefk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_trigram_Laplace(ip_text, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGnCcIN3lrD0",
        "outputId": "bc521b5e-c30f-400b-ca3b-580cf556baa3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textsystems and tidal\n",
            "probability of  generators is  0.02\n",
            "Given sequence: 'systems and tidal', predicted next word: 'generators'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Next Word Prediction Using Bi-Gram Counts with Add - K Smoothening**"
      ],
      "metadata": {
        "id": "TY5rYZPVm-xb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_bigram_K(word_sequence, bigram_counts, unigram_counts, K): #K=0.5-0.01\n",
        "    # Tokenize the input sequence and get the last word\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "    last_word = words_in_sequence[-1]\n",
        "\n",
        "    # Find potential next words based on bigrams starting with last_word\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2), count in bigram_counts.items():\n",
        "        if w1 == last_word:\n",
        "            potential_next_words[w2] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No bigram found starting with '{last_word}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w2 | w1) = Count(w1, w2) / Count(w1)\n",
        "    last_word_unigram_count = unigram_counts.get(last_word, 0)\n",
        "    if last_word_unigram_count == 0:\n",
        "        return f\"'{last_word}' not found in unigram counts. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, bigram_count in potential_next_words.items():\n",
        "        probability = (bigram_count+K) / (last_word_unigram_count+K*V)\n",
        "        print(\"probability of \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts and unigram_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"biology for\"\n",
        "next_word1 = predict_next_word_bigram_K(sequence1, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"zero day\"\n",
        "next_word2 = predict_next_word_bigram_K(sequence2, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n",
        "\n",
        "sequence3 = \"artificial intelligence\"\n",
        "next_word3 = predict_next_word_bigram_K(sequence3, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence3}', predicted next word: '{next_word3}'\")\n",
        "\n",
        "sequence4 = \"transparency in\"\n",
        "next_word4 = predict_next_word_bigram_K(sequence4, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence4}', predicted next word: '{next_word4}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJoBuea9mbFb",
        "outputId": "a178a43a-396e-472b-c63e-cf11c05a2a7b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of advanced is  0.02912621359223301\n",
            "probability of medical is  0.02912621359223301\n",
            "Given sequence: 'biology for', predicted next word: 'advanced'\n",
            "probability of exploits is  0.0297029702970297\n",
            "Given sequence: 'zero day', predicted next word: 'exploits'\n",
            "probability of is is  0.0297029702970297\n",
            "Given sequence: 'artificial intelligence', predicted next word: 'is'\n",
            "probability of predictive is  0.02912621359223301\n",
            "probability of cryptocurrency is  0.02912621359223301\n",
            "Given sequence: 'transparency in', predicted next word: 'predictive'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deployment of Add-K Smoothening based Bi-Gram Model**"
      ],
      "metadata": {
        "id": "UEB6q9oFoSSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_bigram_K(ip_text, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOHJhm_QoZx6",
        "outputId": "0945416b-3ba1-442c-8b7b-e0c0cac4f791"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textstars and\n",
            "probability of research is  0.025210084033613446\n",
            "probability of automation is  0.025210084033613446\n",
            "probability of transformers is  0.025210084033613446\n",
            "probability of entanglement is  0.025210084033613446\n",
            "probability of zero is  0.025210084033613446\n",
            "probability of transparency is  0.025210084033613446\n",
            "probability of tidal is  0.025210084033613446\n",
            "probability of computational is  0.025210084033613446\n",
            "probability of distant is  0.025210084033613446\n",
            "probability of atomic is  0.025210084033613446\n",
            "Given sequence: 'stars and', predicted next word: 'research'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Next Word Prediction Using Tri-Gram Counts with Add - K Smoothening**"
      ],
      "metadata": {
        "id": "-LpwgPNiokr6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_trigram_K(word_sequence, Trigrams_counts, bigram_counts,K): #K=0.5-0.01\n",
        "    # Tokenize the input sequence\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "\n",
        "    # Ensure at least two words for trigram prediction\n",
        "    if len(words_in_sequence) < 2:\n",
        "        return \"Sequence must contain at least two words for trigram prediction.\"\n",
        "\n",
        "    # Get the last two words as a tuple\n",
        "    last_two_words_tuple = tuple(words_in_sequence[-2:])\n",
        "\n",
        "    # Find potential next words based on trigrams starting with the last two words\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2, w3), count in Trigrams_counts.items():\n",
        "        if (w1, w2) == last_two_words_tuple:\n",
        "            potential_next_words[w3] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No trigram found starting with '{' '.join(last_two_words_tuple)}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w3 | w1,w2) = Count(w1, w2, w3) / Count(w1, w2)\n",
        "    # The denominator should be the count of the bigram (w1, w2)\n",
        "    last_two_words_bigram_count = bigram_counts.get(last_two_words_tuple, 0)\n",
        "    if last_two_words_bigram_count == 0:\n",
        "        return f\"'{' '.join(last_two_words_tuple)}' not found as a bigram. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, trigram_count in potential_next_words.items():\n",
        "        probability = (trigram_count+K) / (last_two_words_bigram_count+K*V)\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts, unigram_counts, and Trigrams_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"Machine learning algorithms\"\n",
        "next_word1 = predict_next_word_trigram_K(sequence1, Trigrams_counts, bigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"and tidal generators\"\n",
        "next_word2 = predict_next_word_trigram_K(sequence2, Trigrams_counts, bigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAAZjNF8nTOr",
        "outputId": "84c39f8b-4104-47f2-e713-48bf6f8135e4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of  are is  0.0297029702970297\n",
            "Given sequence: 'Machine learning algorithms', predicted next word: 'are'\n",
            "probability of  bioinformatics is  0.0297029702970297\n",
            "Given sequence: 'and tidal generators', predicted next word: 'bioinformatics'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deployment of Add-K Smoothening based Tri-Gram Model**"
      ],
      "metadata": {
        "id": "l3DHmnUZorC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_trigram_K(ip_text, Trigrams_counts, bigram_counts,0.5)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsmIYasxoNtS",
        "outputId": "320ccd8f-d10f-4d8a-f477-ea18a2d984dd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textsystems and tidal\n",
            "probability of  generators is  0.0297029702970297\n",
            "Given sequence: 'systems and tidal', predicted next word: 'generators'\n"
          ]
        }
      ]
    }
  ]
}