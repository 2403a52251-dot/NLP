{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2ilWiCdi5l9C9WLPmwJ7z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2403a52251-dot/NLP/blob/main/nlp_lab_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import spacy"
      ],
      "metadata": {
        "id": "-00Su6oJZkF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6v3LP1cUCvd"
      },
      "outputs": [],
      "source": [
        "discharge_summary=\"\"\"The patient was admitted for management of community-acquired pneumonia. During hospitalization, the patient received intravenous ceftriaxone and azithromycin with good clinical response. Fever resolved by hospital day two, and oxygen requirements decreased steadily. The patient is discharged in stable condition on oral antibiotics with instructions to follow up with primary care in one week.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.tokenize import word_tokenize\n",
        "word_tokenize(discharge_summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQf_j4f7Zle5",
        "outputId": "8263aa05-19ab-45b8-8228-f08797704218"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'patient',\n",
              " 'was',\n",
              " 'admitted',\n",
              " 'for',\n",
              " 'management',\n",
              " 'of',\n",
              " 'community-acquired',\n",
              " 'pneumonia',\n",
              " '.',\n",
              " 'During',\n",
              " 'hospitalization',\n",
              " ',',\n",
              " 'the',\n",
              " 'patient',\n",
              " 'received',\n",
              " 'intravenous',\n",
              " 'ceftriaxone',\n",
              " 'and',\n",
              " 'azithromycin',\n",
              " 'with',\n",
              " 'good',\n",
              " 'clinical',\n",
              " 'response',\n",
              " '.',\n",
              " 'Fever',\n",
              " 'resolved',\n",
              " 'by',\n",
              " 'hospital',\n",
              " 'day',\n",
              " 'two',\n",
              " ',',\n",
              " 'and',\n",
              " 'oxygen',\n",
              " 'requirements',\n",
              " 'decreased',\n",
              " 'steadily',\n",
              " '.',\n",
              " 'The',\n",
              " 'patient',\n",
              " 'is',\n",
              " 'discharged',\n",
              " 'in',\n",
              " 'stable',\n",
              " 'condition',\n",
              " 'on',\n",
              " 'oral',\n",
              " 'antibiotics',\n",
              " 'with',\n",
              " 'instructions',\n",
              " 'to',\n",
              " 'follow',\n",
              " 'up',\n",
              " 'with',\n",
              " 'primary',\n",
              " 'care',\n",
              " 'in',\n",
              " 'one',\n",
              " 'week',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "sent_tokenize (discharge_summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzcHfZLnbCb5",
        "outputId": "310092f3-bdf5-4090-f341-5978d6b90687"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The patient was admitted for management of community-acquired pneumonia.',\n",
              " 'During hospitalization, the patient received intravenous ceftriaxone and azithromycin with good clinical response.',\n",
              " 'Fever resolved by hospital day two, and oxygen requirements decreased steadily.',\n",
              " 'The patient is discharged in stable condition on oral antibiotics with instructions to follow up with primary care in one week.']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKISnv5sbHu6",
        "outputId": "3d1a29bd-ddad-4ddd-f34a-5fa149cb3270"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words_in_quote = word_tokenize (discharge_summary)\n",
        "words_in_quote"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8vubS9ObWSB",
        "outputId": "78e7ec4d-110e-4c49-f25a-0c467bfbc9aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'patient',\n",
              " 'was',\n",
              " 'admitted',\n",
              " 'for',\n",
              " 'management',\n",
              " 'of',\n",
              " 'community-acquired',\n",
              " 'pneumonia',\n",
              " '.',\n",
              " 'During',\n",
              " 'hospitalization',\n",
              " ',',\n",
              " 'the',\n",
              " 'patient',\n",
              " 'received',\n",
              " 'intravenous',\n",
              " 'ceftriaxone',\n",
              " 'and',\n",
              " 'azithromycin',\n",
              " 'with',\n",
              " 'good',\n",
              " 'clinical',\n",
              " 'response',\n",
              " '.',\n",
              " 'Fever',\n",
              " 'resolved',\n",
              " 'by',\n",
              " 'hospital',\n",
              " 'day',\n",
              " 'two',\n",
              " ',',\n",
              " 'and',\n",
              " 'oxygen',\n",
              " 'requirements',\n",
              " 'decreased',\n",
              " 'steadily',\n",
              " '.',\n",
              " 'The',\n",
              " 'patient',\n",
              " 'is',\n",
              " 'discharged',\n",
              " 'in',\n",
              " 'stable',\n",
              " 'condition',\n",
              " 'on',\n",
              " 'oral',\n",
              " 'antibiotics',\n",
              " 'with',\n",
              " 'instructions',\n",
              " 'to',\n",
              " 'follow',\n",
              " 'up',\n",
              " 'with',\n",
              " 'primary',\n",
              " 'care',\n",
              " 'in',\n",
              " 'one',\n",
              " 'week',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "discharge_summary=\"\"\"The patient was admitted for management of community-acquired pneumonia. During hospitalization, the patient received intravenous ceftriaxone and azithromycin with good clinical response. Fever resolved by hospital day two, and oxygen requirements decreased steadily. The patient is discharged in stable condition on oral antibiotics with instructions to follow up with primary care in one week.\"\"\"\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "words_in_quote = word_tokenize (discharge_summary)\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "filtered_list = []\n",
        "for word in words_in_quote:\n",
        "  if word.casefold() not in stop_words:\n",
        "    filtered_list.append(word)\n",
        "filtered_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJI7Dxx2bm-8",
        "outputId": "ccb1484c-9c09-4584-8c3a-006612e7f886"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['patient',\n",
              " 'admitted',\n",
              " 'management',\n",
              " 'community-acquired',\n",
              " 'pneumonia',\n",
              " '.',\n",
              " 'hospitalization',\n",
              " ',',\n",
              " 'patient',\n",
              " 'received',\n",
              " 'intravenous',\n",
              " 'ceftriaxone',\n",
              " 'azithromycin',\n",
              " 'good',\n",
              " 'clinical',\n",
              " 'response',\n",
              " '.',\n",
              " 'Fever',\n",
              " 'resolved',\n",
              " 'hospital',\n",
              " 'day',\n",
              " 'two',\n",
              " ',',\n",
              " 'oxygen',\n",
              " 'requirements',\n",
              " 'decreased',\n",
              " 'steadily',\n",
              " '.',\n",
              " 'patient',\n",
              " 'discharged',\n",
              " 'stable',\n",
              " 'condition',\n",
              " 'oral',\n",
              " 'antibiotics',\n",
              " 'instructions',\n",
              " 'follow',\n",
              " 'primary',\n",
              " 'care',\n",
              " 'one',\n",
              " 'week',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "stemmer = PorterStemmer()\n",
        "words= word_tokenize (discharge_summary)\n",
        "stemmed_words = [stemmer.stem(word) for word in words]\n",
        "stemmed_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTFy1PPmcPVi",
        "outputId": "9db909c4-7b33-4be4-f038-3b51490f55a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the',\n",
              " 'patient',\n",
              " 'wa',\n",
              " 'admit',\n",
              " 'for',\n",
              " 'manag',\n",
              " 'of',\n",
              " 'community-acquir',\n",
              " 'pneumonia',\n",
              " '.',\n",
              " 'dure',\n",
              " 'hospit',\n",
              " ',',\n",
              " 'the',\n",
              " 'patient',\n",
              " 'receiv',\n",
              " 'intraven',\n",
              " 'ceftriaxon',\n",
              " 'and',\n",
              " 'azithromycin',\n",
              " 'with',\n",
              " 'good',\n",
              " 'clinic',\n",
              " 'respons',\n",
              " '.',\n",
              " 'fever',\n",
              " 'resolv',\n",
              " 'by',\n",
              " 'hospit',\n",
              " 'day',\n",
              " 'two',\n",
              " ',',\n",
              " 'and',\n",
              " 'oxygen',\n",
              " 'requir',\n",
              " 'decreas',\n",
              " 'steadili',\n",
              " '.',\n",
              " 'the',\n",
              " 'patient',\n",
              " 'is',\n",
              " 'discharg',\n",
              " 'in',\n",
              " 'stabl',\n",
              " 'condit',\n",
              " 'on',\n",
              " 'oral',\n",
              " 'antibiot',\n",
              " 'with',\n",
              " 'instruct',\n",
              " 'to',\n",
              " 'follow',\n",
              " 'up',\n",
              " 'with',\n",
              " 'primari',\n",
              " 'care',\n",
              " 'in',\n",
              " 'one',\n",
              " 'week',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "discharge_summary=\"\"\"The patient was admitted for management of community-acquired pneumonia. During hospitalization, the patient received intravenous ceftriaxone and azithromycin with good clinical response. Fever resolved by hospital day two, and oxygen requirements decreased steadily. The patient is discharged in stable condition on oral antibiotics with instructions to follow up with primary care in one week.\"\"\"\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "snowball = SnowballStemmer (language='english')\n",
        "words = word_tokenize (discharge_summary)\n",
        "for word in words:\n",
        "  print(word, \"---->\", snowball.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpmHS6mwcmgZ",
        "outputId": "ff06f592-e29c-4a9e-c50d-87353dce1aac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The ----> the\n",
            "patient ----> patient\n",
            "was ----> was\n",
            "admitted ----> admit\n",
            "for ----> for\n",
            "management ----> manag\n",
            "of ----> of\n",
            "community-acquired ----> community-acquir\n",
            "pneumonia ----> pneumonia\n",
            ". ----> .\n",
            "During ----> dure\n",
            "hospitalization ----> hospit\n",
            ", ----> ,\n",
            "the ----> the\n",
            "patient ----> patient\n",
            "received ----> receiv\n",
            "intravenous ----> intraven\n",
            "ceftriaxone ----> ceftriaxon\n",
            "and ----> and\n",
            "azithromycin ----> azithromycin\n",
            "with ----> with\n",
            "good ----> good\n",
            "clinical ----> clinic\n",
            "response ----> respons\n",
            ". ----> .\n",
            "Fever ----> fever\n",
            "resolved ----> resolv\n",
            "by ----> by\n",
            "hospital ----> hospit\n",
            "day ----> day\n",
            "two ----> two\n",
            ", ----> ,\n",
            "and ----> and\n",
            "oxygen ----> oxygen\n",
            "requirements ----> requir\n",
            "decreased ----> decreas\n",
            "steadily ----> steadili\n",
            ". ----> .\n",
            "The ----> the\n",
            "patient ----> patient\n",
            "is ----> is\n",
            "discharged ----> discharg\n",
            "in ----> in\n",
            "stable ----> stabl\n",
            "condition ----> condit\n",
            "on ----> on\n",
            "oral ----> oral\n",
            "antibiotics ----> antibiot\n",
            "with ----> with\n",
            "instructions ----> instruct\n",
            "to ----> to\n",
            "follow ----> follow\n",
            "up ----> up\n",
            "with ----> with\n",
            "primary ----> primari\n",
            "care ----> care\n",
            "in ----> in\n",
            "one ----> one\n",
            "week ----> week\n",
            ". ----> .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import LancasterStemmer\n",
        "Lanc = LancasterStemmer()\n",
        "words = word_tokenize (discharge_summary)\n",
        "for word in words:\n",
        "  print(word, \"---->\", Lanc.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRtty4dMdR2S",
        "outputId": "d79cbd3d-13f5-4c0a-d62e-8d2051b6d1fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The ----> the\n",
            "patient ----> paty\n",
            "was ----> was\n",
            "admitted ----> admit\n",
            "for ----> for\n",
            "management ----> man\n",
            "of ----> of\n",
            "community-acquired ----> community-acquired\n",
            "pneumonia ----> pneumon\n",
            ". ----> .\n",
            "During ----> dur\n",
            "hospitalization ----> hospit\n",
            ", ----> ,\n",
            "the ----> the\n",
            "patient ----> paty\n",
            "received ----> receiv\n",
            "intravenous ----> intrav\n",
            "ceftriaxone ----> ceftriaxon\n",
            "and ----> and\n",
            "azithromycin ----> azithromycin\n",
            "with ----> with\n",
            "good ----> good\n",
            "clinical ----> clin\n",
            "response ----> respons\n",
            ". ----> .\n",
            "Fever ----> fev\n",
            "resolved ----> resolv\n",
            "by ----> by\n",
            "hospital ----> hospit\n",
            "day ----> day\n",
            "two ----> two\n",
            ", ----> ,\n",
            "and ----> and\n",
            "oxygen ----> oxyg\n",
            "requirements ----> requir\n",
            "decreased ----> decreas\n",
            "steadily ----> steady\n",
            ". ----> .\n",
            "The ----> the\n",
            "patient ----> paty\n",
            "is ----> is\n",
            "discharged ----> discharg\n",
            "in ----> in\n",
            "stable ----> stabl\n",
            "condition ----> condit\n",
            "on ----> on\n",
            "oral ----> or\n",
            "antibiotics ----> antibiot\n",
            "with ----> with\n",
            "instructions ----> instruct\n",
            "to ----> to\n",
            "follow ----> follow\n",
            "up ----> up\n",
            "with ----> with\n",
            "primary ----> prim\n",
            "care ----> car\n",
            "in ----> in\n",
            "one ----> on\n",
            "week ----> week\n",
            ". ----> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import RegexpStemmer\n",
        "regexp = RegexpStemmer('ing$|$| e$|able$', min=4)\n",
        "words = word_tokenize (discharge_summary)\n",
        "for word in words:\n",
        "  print (word, \"---->\", regexp.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6L4Py8rePNH",
        "outputId": "4389df55-6093-44d5-825c-8012ba644500"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The ----> The\n",
            "patient ----> patient\n",
            "was ----> was\n",
            "admitted ----> admitted\n",
            "for ----> for\n",
            "management ----> management\n",
            "of ----> of\n",
            "community-acquired ----> community-acquired\n",
            "pneumonia ----> pneumonia\n",
            ". ----> .\n",
            "During ----> Dur\n",
            "hospitalization ----> hospitalization\n",
            ", ----> ,\n",
            "the ----> the\n",
            "patient ----> patient\n",
            "received ----> received\n",
            "intravenous ----> intravenous\n",
            "ceftriaxone ----> ceftriaxone\n",
            "and ----> and\n",
            "azithromycin ----> azithromycin\n",
            "with ----> with\n",
            "good ----> good\n",
            "clinical ----> clinical\n",
            "response ----> response\n",
            ". ----> .\n",
            "Fever ----> Fever\n",
            "resolved ----> resolved\n",
            "by ----> by\n",
            "hospital ----> hospital\n",
            "day ----> day\n",
            "two ----> two\n",
            ", ----> ,\n",
            "and ----> and\n",
            "oxygen ----> oxygen\n",
            "requirements ----> requirements\n",
            "decreased ----> decreased\n",
            "steadily ----> steadily\n",
            ". ----> .\n",
            "The ----> The\n",
            "patient ----> patient\n",
            "is ----> is\n",
            "discharged ----> discharged\n",
            "in ----> in\n",
            "stable ----> st\n",
            "condition ----> condition\n",
            "on ----> on\n",
            "oral ----> oral\n",
            "antibiotics ----> antibiotics\n",
            "with ----> with\n",
            "instructions ----> instructions\n",
            "to ----> to\n",
            "follow ----> follow\n",
            "up ----> up\n",
            "with ----> with\n",
            "primary ----> primary\n",
            "care ----> care\n",
            "in ----> in\n",
            "one ----> one\n",
            "week ----> week\n",
            ". ----> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "discharge_summary=\"\"\"The patient was admitted for management of community-acquired pneumonia. During hospitalization, the patient received intravenous ceftriaxone and azithromycin with good clinical response. Fever resolved by hospital day two, and oxygen requirements decreased steadily. The patient is discharged in stable condition on oral antibiotics with instructions to follow up with primary care in one week.\"\"\"\n",
        "import nltk\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "words = word_tokenize (discharge_summary)\n",
        "for word in words:\n",
        "  print(word, \"---->\", lemmatizer.lemmatize(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXkCpBQoe0gF",
        "outputId": "74f58087-2a8d-4471-a9a7-05defd18d8cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The ----> The\n",
            "patient ----> patient\n",
            "was ----> wa\n",
            "admitted ----> admitted\n",
            "for ----> for\n",
            "management ----> management\n",
            "of ----> of\n",
            "community-acquired ----> community-acquired\n",
            "pneumonia ----> pneumonia\n",
            ". ----> .\n",
            "During ----> During\n",
            "hospitalization ----> hospitalization\n",
            ", ----> ,\n",
            "the ----> the\n",
            "patient ----> patient\n",
            "received ----> received\n",
            "intravenous ----> intravenous\n",
            "ceftriaxone ----> ceftriaxone\n",
            "and ----> and\n",
            "azithromycin ----> azithromycin\n",
            "with ----> with\n",
            "good ----> good\n",
            "clinical ----> clinical\n",
            "response ----> response\n",
            ". ----> .\n",
            "Fever ----> Fever\n",
            "resolved ----> resolved\n",
            "by ----> by\n",
            "hospital ----> hospital\n",
            "day ----> day\n",
            "two ----> two\n",
            ", ----> ,\n",
            "and ----> and\n",
            "oxygen ----> oxygen\n",
            "requirements ----> requirement\n",
            "decreased ----> decreased\n",
            "steadily ----> steadily\n",
            ". ----> .\n",
            "The ----> The\n",
            "patient ----> patient\n",
            "is ----> is\n",
            "discharged ----> discharged\n",
            "in ----> in\n",
            "stable ----> stable\n",
            "condition ----> condition\n",
            "on ----> on\n",
            "oral ----> oral\n",
            "antibiotics ----> antibiotic\n",
            "with ----> with\n",
            "instructions ----> instruction\n",
            "to ----> to\n",
            "follow ----> follow\n",
            "up ----> up\n",
            "with ----> with\n",
            "primary ----> primary\n",
            "care ----> care\n",
            "in ----> in\n",
            "one ----> one\n",
            "week ----> week\n",
            ". ----> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer, SnowballStemmer, LancasterStemmer, RegexpStemmer, WordNetLemmatizer\n",
        "porter = PorterStemmer()\n",
        "lancaster = LancasterStemmer()\n",
        "snowball = SnowballStemmer (language='english')\n",
        "regexp = RegexpStemmer('ing$|$|e$|able$', min=4)\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "word_list = [\"friend\", \"friendship\", \"friends\", \"friendships\"]\n",
        "print(\"{0:20}{1:20}{2:20}{3:30}{4:40}{5:30}\".format(\"Word\", \"Porter Stemmer\", \"Snowball Stemmer\", \"Lancaster Stemmer\", \"Regexp Stemmer\", \"WordNet Lemmatizer\"))\n",
        "print(\"-\"*180)\n",
        "for word in word_list:\n",
        "  print(\"{0:20}{1:20}{2:20}{3:30}{4:40}{5:30}\".format(word, porter.stem (word), snowball.stem (word), lancaster.stem (word), regexp.stem(word), lemmatizer.lemmatize(word)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nctOYUzdfklA",
        "outputId": "38094d0e-ed2d-4e4d-89b8-915fcf25c728"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word                Porter Stemmer      Snowball Stemmer    Lancaster Stemmer             Regexp Stemmer                          WordNet Lemmatizer            \n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "friend              friend              friend              friend                        friend                                  friend                        \n",
            "friendship          friendship          friendship          friend                        friendship                              friendship                    \n",
            "friends             friend              friend              friend                        friends                                 friend                        \n",
            "friendships         friendship          friendship          friend                        friendships                             friendship                    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"worst\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "lEsgwzi4zzMI",
        "outputId": "6a48a132-72c4-417f-9b96-dc41679a4b34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'worst'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"worst\", pos=\"a\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3JvSFOyvz4Cu",
        "outputId": "e3f7fe09-06e2-42e3-ee35-b5864f580728"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'bad'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SRUniversity=\"\"\"The SR University campus is located in Ananthasagar village of Hasanparthy Mandal in Warangal, Telangana, India.\n",
        "It is in 150 acres, with both separate hostel facilities for boys and girls.\"\"\""
      ],
      "metadata": {
        "id": "sZ6riOVIxg_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(SRUniversity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOjzwP5Wxs_0",
        "outputId": "92e84059-2091-4ab4-d976-48ac67bcec4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The SR University campus is located in Ananthasagar village of Hasanparthy Mandal in Warangal, Telangana, India.\n",
            "It is in 150 acres, with both separate hostel facilities for boys and girls.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab') # Added to resolve the LookupError\n",
        "from nltk.tokenize import word_tokenize\n",
        "word_tokenize(SRUniversity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0doUKQ9-x63G",
        "outputId": "b6aeff7e-08ee-4c52-f639-a3f40529f1bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'SR',\n",
              " 'University',\n",
              " 'campus',\n",
              " 'is',\n",
              " 'located',\n",
              " 'in',\n",
              " 'Ananthasagar',\n",
              " 'village',\n",
              " 'of',\n",
              " 'Hasanparthy',\n",
              " 'Mandal',\n",
              " 'in',\n",
              " 'Warangal',\n",
              " ',',\n",
              " 'Telangana',\n",
              " ',',\n",
              " 'India',\n",
              " '.',\n",
              " 'It',\n",
              " 'is',\n",
              " 'in',\n",
              " '150',\n",
              " 'acres',\n",
              " ',',\n",
              " 'with',\n",
              " 'both',\n",
              " 'separate',\n",
              " 'hostel',\n",
              " 'facilities',\n",
              " 'for',\n",
              " 'boys',\n",
              " 'and',\n",
              " 'girls',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "sent_tokenize(SRUniversity)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGlQncb5x9ad",
        "outputId": "a73fec50-d2e7-4aa7-bfdb-9b981cfeeaf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The SR University campus is located in Ananthasagar village of Hasanparthy Mandal in Warangal, Telangana, India.',\n",
              " 'It is in 150 acres, with both separate hostel facilities for boys and girls.']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkHxupVTyHBR",
        "outputId": "371d710e-9b84-422f-99d0-c41310bbed0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words_in_quote = word_tokenize(SRUniversity)\n",
        "words_in_quote"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1v2I4fjByJzj",
        "outputId": "b97c1748-6cd1-4a51-f743-75a1507d6b02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'SR',\n",
              " 'University',\n",
              " 'campus',\n",
              " 'is',\n",
              " 'located',\n",
              " 'in',\n",
              " 'Ananthasagar',\n",
              " 'village',\n",
              " 'of',\n",
              " 'Hasanparthy',\n",
              " 'Mandal',\n",
              " 'in',\n",
              " 'Warangal',\n",
              " ',',\n",
              " 'Telangana',\n",
              " ',',\n",
              " 'India',\n",
              " '.',\n",
              " 'It',\n",
              " 'is',\n",
              " 'in',\n",
              " '150',\n",
              " 'acres',\n",
              " ',',\n",
              " 'with',\n",
              " 'both',\n",
              " 'separate',\n",
              " 'hostel',\n",
              " 'facilities',\n",
              " 'for',\n",
              " 'boys',\n",
              " 'and',\n",
              " 'girls',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words(\"english\"))\n",
        "filtered_list = []\n",
        "for word in words_in_quote:\n",
        "  if word.casefold() not in stop_words:\n",
        "    filtered_list.append(word)\n",
        "filtered_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZP0PMxzyLuJ",
        "outputId": "1256860e-3771-4f57-c1ed-104940ec4add"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['SR',\n",
              " 'University',\n",
              " 'campus',\n",
              " 'located',\n",
              " 'Ananthasagar',\n",
              " 'village',\n",
              " 'Hasanparthy',\n",
              " 'Mandal',\n",
              " 'Warangal',\n",
              " ',',\n",
              " 'Telangana',\n",
              " ',',\n",
              " 'India',\n",
              " '.',\n",
              " '150',\n",
              " 'acres',\n",
              " ',',\n",
              " 'separate',\n",
              " 'hostel',\n",
              " 'facilities',\n",
              " 'boys',\n",
              " 'girls',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "stemmer = PorterStemmer()\n",
        "words = word_tokenize(SRUniversity)\n",
        "stemmed_words = [stemmer.stem(word) for word in words]\n",
        "stemmed_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLOu_-6lyOpr",
        "outputId": "729fd0aa-fc0e-4566-ab5d-4bdd762134b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the',\n",
              " 'sr',\n",
              " 'univers',\n",
              " 'campu',\n",
              " 'is',\n",
              " 'locat',\n",
              " 'in',\n",
              " 'ananthasagar',\n",
              " 'villag',\n",
              " 'of',\n",
              " 'hasanparthi',\n",
              " 'mandal',\n",
              " 'in',\n",
              " 'warang',\n",
              " ',',\n",
              " 'telangana',\n",
              " ',',\n",
              " 'india',\n",
              " '.',\n",
              " 'it',\n",
              " 'is',\n",
              " 'in',\n",
              " '150',\n",
              " 'acr',\n",
              " ',',\n",
              " 'with',\n",
              " 'both',\n",
              " 'separ',\n",
              " 'hostel',\n",
              " 'facil',\n",
              " 'for',\n",
              " 'boy',\n",
              " 'and',\n",
              " 'girl',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "snowball = SnowballStemmer(language='english')\n",
        "words = word_tokenize(SRUniversity)\n",
        "for word in words:\n",
        "    print(word,\"--->\",snowball.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlazjGd8yRUi",
        "outputId": "160318d1-d737-49ab-a4b1-e540ee0e8cc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The ---> the\n",
            "SR ---> sr\n",
            "University ---> univers\n",
            "campus ---> campus\n",
            "is ---> is\n",
            "located ---> locat\n",
            "in ---> in\n",
            "Ananthasagar ---> ananthasagar\n",
            "village ---> villag\n",
            "of ---> of\n",
            "Hasanparthy ---> hasanparthi\n",
            "Mandal ---> mandal\n",
            "in ---> in\n",
            "Warangal ---> warang\n",
            ", ---> ,\n",
            "Telangana ---> telangana\n",
            ", ---> ,\n",
            "India ---> india\n",
            ". ---> .\n",
            "It ---> it\n",
            "is ---> is\n",
            "in ---> in\n",
            "150 ---> 150\n",
            "acres ---> acr\n",
            ", ---> ,\n",
            "with ---> with\n",
            "both ---> both\n",
            "separate ---> separ\n",
            "hostel ---> hostel\n",
            "facilities ---> facil\n",
            "for ---> for\n",
            "boys ---> boy\n",
            "and ---> and\n",
            "girls ---> girl\n",
            ". ---> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import LancasterStemmer\n",
        "Lanc = LancasterStemmer()\n",
        "words = word_tokenize(SRUniversity)\n",
        "for word in words:\n",
        "    print(word,\"--->\",Lanc.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPv8KTSHyWMK",
        "outputId": "09c09c69-49e3-4d70-c3e9-08ce57ddf8ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The ---> the\n",
            "SR ---> sr\n",
            "University ---> univers\n",
            "campus ---> camp\n",
            "is ---> is\n",
            "located ---> loc\n",
            "in ---> in\n",
            "Ananthasagar ---> ananthasag\n",
            "village ---> vil\n",
            "of ---> of\n",
            "Hasanparthy ---> hasanparthy\n",
            "Mandal ---> mand\n",
            "in ---> in\n",
            "Warangal ---> warang\n",
            ", ---> ,\n",
            "Telangana ---> telangan\n",
            ", ---> ,\n",
            "India ---> ind\n",
            ". ---> .\n",
            "It ---> it\n",
            "is ---> is\n",
            "in ---> in\n",
            "150 ---> 150\n",
            "acres ---> acr\n",
            ", ---> ,\n",
            "with ---> with\n",
            "both ---> both\n",
            "separate ---> sep\n",
            "hostel ---> hostel\n",
            "facilities ---> facil\n",
            "for ---> for\n",
            "boys ---> boy\n",
            "and ---> and\n",
            "girls ---> girl\n",
            ". ---> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import RegexpStemmer\n",
        "regexp = RegexpStemmer('ing|e', min=4)\n",
        "words = word_tokenize(SRUniversity)\n",
        "for word in words:\n",
        "    print(word,\"--->\",regexp.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTjQLPHSyYBo",
        "outputId": "084b8218-29b5-4c0d-af34-b88290a800cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The ---> The\n",
            "SR ---> SR\n",
            "University ---> Univrsity\n",
            "campus ---> campus\n",
            "is ---> is\n",
            "located ---> locatd\n",
            "in ---> in\n",
            "Ananthasagar ---> Ananthasagar\n",
            "village ---> villag\n",
            "of ---> of\n",
            "Hasanparthy ---> Hasanparthy\n",
            "Mandal ---> Mandal\n",
            "in ---> in\n",
            "Warangal ---> Warangal\n",
            ", ---> ,\n",
            "Telangana ---> Tlangana\n",
            ", ---> ,\n",
            "India ---> India\n",
            ". ---> .\n",
            "It ---> It\n",
            "is ---> is\n",
            "in ---> in\n",
            "150 ---> 150\n",
            "acres ---> acrs\n",
            ", ---> ,\n",
            "with ---> with\n",
            "both ---> both\n",
            "separate ---> sparat\n",
            "hostel ---> hostl\n",
            "facilities ---> facilitis\n",
            "for ---> for\n",
            "boys ---> boys\n",
            "and ---> and\n",
            "girls ---> girls\n",
            ". ---> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('omw-1.4')\n",
        "nltk.download('wordnet') # Added to resolve the LookupError\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "words = word_tokenize(SRUniversity)\n",
        "for word in words:\n",
        "    print(word,\"--->\",lemmatizer.lemmatize(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iV7Vmj5vyfJS",
        "outputId": "85312fc0-3ac0-45e6-c016-f671a533edc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The ---> The\n",
            "SR ---> SR\n",
            "University ---> University\n",
            "campus ---> campus\n",
            "is ---> is\n",
            "located ---> located\n",
            "in ---> in\n",
            "Ananthasagar ---> Ananthasagar\n",
            "village ---> village\n",
            "of ---> of\n",
            "Hasanparthy ---> Hasanparthy\n",
            "Mandal ---> Mandal\n",
            "in ---> in\n",
            "Warangal ---> Warangal\n",
            ", ---> ,\n",
            "Telangana ---> Telangana\n",
            ", ---> ,\n",
            "India ---> India\n",
            ". ---> .\n",
            "It ---> It\n",
            "is ---> is\n",
            "in ---> in\n",
            "150 ---> 150\n",
            "acres ---> acre\n",
            ", ---> ,\n",
            "with ---> with\n",
            "both ---> both\n",
            "separate ---> separate\n",
            "hostel ---> hostel\n",
            "facilities ---> facility\n",
            "for ---> for\n",
            "boys ---> boy\n",
            "and ---> and\n",
            "girls ---> girl\n",
            ". ---> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"worst\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "kwCXZcT1yncj",
        "outputId": "e96d30d5-b251-48cb-870e-87c8e9780527"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'worst'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"worst\", pos=\"a\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "8J2iDJ8-yphR",
        "outputId": "8a66c284-783a-4a83-ae66-cfa84ce58bdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'bad'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NLP=\"\"\"NLP models are transforming the world rapidly\"\"\""
      ],
      "metadata": {
        "id": "lsp3R5Yoy4N5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(NLP)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYriFqRVy7eX",
        "outputId": "83a2e6f6-6713-4543-eb0d-6cbd8897b377"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLP models are transforming the world rapidly\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "word_tokenize(NLP)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nb0C3ZNIy9Rm",
        "outputId": "3137feb4-6259-40e7-de7f-d8626d2c6497"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['NLP', 'models', 'are', 'transforming', 'the', 'world', 'rapidly']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "sent_tokenize(NLP)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_06h6G7zCSD",
        "outputId": "3fffae21-ca23-4b94-cce4-1d6bad7a9e6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['NLP models are transforming the world rapidly']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XujNtLNzAod",
        "outputId": "e66cfd1b-cfb6-4d2d-f6ab-934490d9d957"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words_in_quote = word_tokenize(SRUniversity)\n",
        "words_in_quote"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEK5jWTxzI1F",
        "outputId": "f0c8fc95-d703-4d67-8b70-843ecf724ae5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'SR',\n",
              " 'University',\n",
              " 'campus',\n",
              " 'is',\n",
              " 'located',\n",
              " 'in',\n",
              " 'Ananthasagar',\n",
              " 'village',\n",
              " 'of',\n",
              " 'Hasanparthy',\n",
              " 'Mandal',\n",
              " 'in',\n",
              " 'Warangal',\n",
              " ',',\n",
              " 'Telangana',\n",
              " ',',\n",
              " 'India',\n",
              " '.',\n",
              " 'It',\n",
              " 'is',\n",
              " 'in',\n",
              " '150',\n",
              " 'acres',\n",
              " ',',\n",
              " 'with',\n",
              " 'both',\n",
              " 'separate',\n",
              " 'hostel',\n",
              " 'facilities',\n",
              " 'for',\n",
              " 'boys',\n",
              " 'and',\n",
              " 'girls',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words(\"english\"))\n",
        "filtered_list = []\n",
        "for word in words_in_quote:\n",
        "  if word.casefold() not in stop_words:\n",
        "    filtered_list.append(word)\n",
        "filtered_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yc79RaYHzLVE",
        "outputId": "6f327381-fd8f-4ef7-ad56-b96c56c4229d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['SR',\n",
              " 'University',\n",
              " 'campus',\n",
              " 'located',\n",
              " 'Ananthasagar',\n",
              " 'village',\n",
              " 'Hasanparthy',\n",
              " 'Mandal',\n",
              " 'Warangal',\n",
              " ',',\n",
              " 'Telangana',\n",
              " ',',\n",
              " 'India',\n",
              " '.',\n",
              " '150',\n",
              " 'acres',\n",
              " ',',\n",
              " 'separate',\n",
              " 'hostel',\n",
              " 'facilities',\n",
              " 'boys',\n",
              " 'girls',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "stemmer = PorterStemmer()\n",
        "words = word_tokenize(NLP)\n",
        "stemmed_words = [stemmer.stem(word) for word in words]\n",
        "stemmed_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsCy-pbyzN1s",
        "outputId": "0bb0e472-2d6a-4344-aab7-33be068c7566"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['nlp', 'model', 'are', 'transform', 'the', 'world', 'rapidli']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "snowball = SnowballStemmer(language='english')\n",
        "words = word_tokenize(NLP)\n",
        "for word in words:\n",
        "    print(word,\"--->\",snowball.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9aXUSwczUHX",
        "outputId": "13277f0c-5cbe-4db3-e349-e677677bb402"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLP ---> nlp\n",
            "models ---> model\n",
            "are ---> are\n",
            "transforming ---> transform\n",
            "the ---> the\n",
            "world ---> world\n",
            "rapidly ---> rapid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import LancasterStemmer\n",
        "Lanc = LancasterStemmer()\n",
        "words = word_tokenize(NLP)\n",
        "for word in words:\n",
        "    print(word,\"--->\",Lanc.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etilqqdCzZyn",
        "outputId": "e2b26fa0-75e6-4660-ecb6-73d8b51d5ab1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLP ---> nlp\n",
            "models ---> model\n",
            "are ---> ar\n",
            "transforming ---> transform\n",
            "the ---> the\n",
            "world ---> world\n",
            "rapidly ---> rapid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import RegexpStemmer\n",
        "regexp = RegexpStemmer('ing|e', min=4)\n",
        "words = word_tokenize(NLP)\n",
        "for word in words:\n",
        "    print(word,\"--->\",Lanc.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8aCianHzfGv",
        "outputId": "77073092-ac62-46f9-dafe-7a91c1c54238"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLP ---> nlp\n",
            "models ---> model\n",
            "are ---> ar\n",
            "transforming ---> transform\n",
            "the ---> the\n",
            "world ---> world\n",
            "rapidly ---> rapid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('omw-1.4')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "words = word_tokenize(SRUniversity)\n",
        "for word in words:\n",
        "    print(word,\"--->\",lemmatizer.lemmatize(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kq0vn8e8znte",
        "outputId": "3e1d4d12-e62d-4a69-b8cf-aba14e173c14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The ---> The\n",
            "SR ---> SR\n",
            "University ---> University\n",
            "campus ---> campus\n",
            "is ---> is\n",
            "located ---> located\n",
            "in ---> in\n",
            "Ananthasagar ---> Ananthasagar\n",
            "village ---> village\n",
            "of ---> of\n",
            "Hasanparthy ---> Hasanparthy\n",
            "Mandal ---> Mandal\n",
            "in ---> in\n",
            "Warangal ---> Warangal\n",
            ", ---> ,\n",
            "Telangana ---> Telangana\n",
            ", ---> ,\n",
            "India ---> India\n",
            ". ---> .\n",
            "It ---> It\n",
            "is ---> is\n",
            "in ---> in\n",
            "150 ---> 150\n",
            "acres ---> acre\n",
            ", ---> ,\n",
            "with ---> with\n",
            "both ---> both\n",
            "separate ---> separate\n",
            "hostel ---> hostel\n",
            "facilities ---> facility\n",
            "for ---> for\n",
            "boys ---> boy\n",
            "and ---> and\n",
            "girls ---> girl\n",
            ". ---> .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"worst\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "2kmd4ADjzqfg",
        "outputId": "36dd2090-f0e0-4500-ffb4-adea1c634b1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'worst'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"worst\", pos=\"a\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "RvhCZxfKzrZV",
        "outputId": "d2bff437-c570-4d1b-a3ad-a77b846f9a82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'bad'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    }
  ]
}